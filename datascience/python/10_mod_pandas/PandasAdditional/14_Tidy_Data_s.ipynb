{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 14 Tidy Data\n",
    "File(s) needed: pew.csv, billboard.csv, country_timeseries.csv, weather.csv\n",
    "\n",
    "Tidy data is a way to structure data sets to make it easy to perform an analysis on them. A goal of data preparation should be to make data tidy.\n",
    "\n",
    "What is tidy data?\n",
    "- each column is a variable\n",
    "- each row is an observation\n",
    "- each type of observational unit forms a table\n",
    "\n",
    "That may not seem like a big deal but that is because we almost always use very clean, tidy data in classes. Real world data is messy. We will look at the different ways we can work toward tidy data by looking at some untidy examples and cleaning them up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns contain values, not variables\n",
    "This is especially common for data collection or presentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas\n",
    "\n",
    "\n",
    "# set the display option to be able to see all columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep one column fixed\n",
    "This data set has columns that contain values instead of variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the Pew Research Center data on income and religion in America\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only variable column is 'religion.' Income is spread across several columns. A good shape for presentations but not good for further analysis. We need to reshape the data so we have variables for religion, income, and the counts at each of those intersections.\n",
    "\n",
    "This is known as \"wide\" data, because the variables are spread out. When we make it tidy, it will be considered \"long\" data.\n",
    "\n",
    "We'll use the pandas function `melt` to reshape this data. A few important parameters of `melt` are\n",
    "- `id_vars`: a string or a list of strings that represents the variables that don't change.\n",
    "- `value_vars`: the column(s) you want to melt. Default: all columns not in `id_vars`\n",
    "- `var_name`: the name for the new column after the `value_vars` columns have been melted into one column. Default: called _variable_\n",
    "- `value_name`: the name for the new column that holds the values of `var_name`. Default: called _value_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the data into a long table.\n",
    "# We don't need to specify a value for value_vars because we are\n",
    "#   melting all columns except religion.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the default values so the columns get meaningful names\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keep multiple columns fixed\n",
    "What if we have more than one column that is okay as it is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load billboard data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Weekly data is spread out across multiple columns but everything else is fine. We'll keep those columns fixed and melt the weekly data. Here again we won't need to specify `value_vars` because it will be the default of everything that isn't specified in `id_vars`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the billboard data into long form\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at the results in other ways\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columns contain multiple variables\n",
    "Common with healthcare data. We'll use data on Ebola cases to see an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the ebola data set\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the columns `Cases_Guinea` and `Deaths_Guinea`. These two columns each contain data on two variables: country name and number of cases (for Cases_Guinea) and country name and number of deaths (for Deaths_Guinea). So we should really melt those into a patient's status and country. First, we'll get the data out of the \"wide\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert from wide to long data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split and add columns\n",
    "Looking at the values that are now in the `variable` column, we would like to split the columns into two variables: status and country. In this data, that happens at the underscore (`_`) in the data value. For example, the first row had 'Cases_Guinea' in the variable column. We can use a string method called `split()` to create the two values. We'll see more string methods later, but for now we can know that the `split()` method takes as an argument the character to use as the splitting point and it returns a list with the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the variable column in the data frame. Access the string methods with str and\n",
    "#   split the column at the _\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to assign those values to a new column. First, we extract the parts we need. For the status values, we need the zero element of the results list *variable_split*, and for the country values we need the 1 element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the values needed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can add them to our dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check some values to make sure everything is where it should be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variables in both rows and columns\n",
    "Some times data will be formatted so there are variables in both rows and columns. That is a combination of what we have seen so far, so we have already seen most of the methods used to tidy it up.\n",
    "\n",
    "We'll use weather data to look at how we deal with this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load the weather data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at info() for the weather data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the 'element' column. It has values for tmax and tmin, the high and low temperatures respectively. They need to be split into new columns. \n",
    "\n",
    "Then there are all the 'd' columns. They represent daily temperatures and need to be melted into one variable column.\n",
    "\n",
    "First, we'll melt the day values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Melt the day values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What about the tail?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We still need to pivot the element column into two columns. We can use the `pivot_table()` method of the data frame to do this. It works like `melt()`, just in the opposite direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the element column into two columns that get the temp values\n",
    "# The data frame index will be a hierarchical mess if we don't reset it.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `pivot_table()` method above, the arguments are\n",
    "- `index`: the columns to leave alone\n",
    "- `columns`: the column(s) to pivot into new columns\n",
    "- `values`: the column(s) that hold the data values to pivot\n",
    "\n",
    "After all this manipulation, the index values for the rows are completely jumbled up. `reset_index()` fixes that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we only have the non-null data left in our data frame\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the data by the values in month and day columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiple observational units in one table (nonnormalized)\n",
    "Are we looking at data that is not normalized? See if any values are repeated across rows.\n",
    "\n",
    "Let's look at an example from the Billboard data we tidied earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell only needs to be run if the Billboard data is not already in memory\n",
    "billboard = pd.read_csv('../data/billboard.csv')\n",
    "billboard_long = pd.melt(billboard,\n",
    "                        id_vars=['year','artist','track','time','date.entered'],\n",
    "                        var_name='week',\n",
    "                        value_name='rank')\n",
    "billboard_long.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look at a subset of the data for one track.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the table repeats the track info with every weekly ranking data point. The track info should really be stored in a separate table. Year, artist, track, and time should be moved to a new data frame with a unique ID number and without all the duplication. Then we can use this ID to link the tables when we need to. \n",
    "\n",
    "Start by subsetting the track info to a new data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset the track info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate values - we first did this in the missing data notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign a unique ID number to each row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the ID number to match the new song data frame to the ranking data in the original data set.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at what the `merge()` method does and its arguments.\n",
    "- it is a method of a data frame, so it is called from one frame. The first argument listed is the other data frame to merge.\n",
    "- the `on` parameter is the column(s) common to both data frames to match up in order to accomplish the merge.\n",
    "\n",
    "More info is available on the pandas documentation site\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.merge.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, get rid of the unneeded columns in the ranking data frame.\n",
    "# We can do this by either subsetting or dropping columns. Here we subset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
